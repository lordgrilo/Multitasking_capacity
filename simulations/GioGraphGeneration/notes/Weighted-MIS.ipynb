{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on the sampling of weighted graphs for MIS estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No weights on the nodes (tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define $$G=(V,E,\\omega)$$ as a weighted graph on the vertex set V, with the complete edgeset $$E = V \\times V$$ weighted by the weight function $$\\omega: E \\to \\mathbf{R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us further consider the weight function as inducing a probability on the edges by normalizing the weight function in $(0,1)$, $$\\tilde{\\omega} = \\frac{\\omega}{\\max_E{\\omega}}$$ graphs in the following way. To a certain instanced graph \n",
    "$$g = (V,E_g) \\in W$$\n",
    "where $W$ is the space of all graphs on the nodeset $V$, we associate the probability $p(g)$:    \n",
    "$$p(g) = \\prod_{e \\in E_g} \\tilde{\\omega_e} \\prod_{e \\in E \\setminus E_g} (1-\\tilde{\\omega_e})$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each graph $g$ one can then calculate the MIS and obtain the corresponding (normalized) maximum independence number $\\theta : W \\to \\mathbf{R}$ and finally try to calculate $E_G[\\theta]$ in the form:\n",
    "$$ E_G[\\theta] = \\sum_g \\theta(g)p(g) $$  \n",
    "There are two problems:\n",
    "1. how to sample the space of graphs in a way that is meaningful\n",
    "2. substitute the analytical expression for $\\theta$ in the sum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposal for the sampling: ** $p(g)$ is written as a product of independent, uncorrelated probabilities at this stage (even if we consider the possibility to generalized $\\omega$ to more refined functions). If we keep this assumption, then the generation of the instanced graphs becomes very straightforward:  \n",
    "\n",
    "- for each possible edge, flip a coin;\n",
    "- with probability $\\omega_e$ add the edge, otherwise do nothing;\n",
    "\n",
    "The total probability of the graph is that of all the edges being present. \n",
    "In this way it becomes possible to do MC simulations, which in the crudest form looks like this:\n",
    "- generate a sample $g_i$, $i=1,2,\\ldots,n$ from $p_g$\n",
    "- calculate $I = \\frac{1}{n} \\sum_{i=0}^n \\theta(g_i)$\n",
    "- by LOLN $I$ is guaranteed to converge to $I \\to \\sum_g \\theta(g) p(g)$\n",
    "\n",
    "NOTE: one needs to keep the variance under control!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposal for the independence number estimate: **\n",
    "Basically, if we can prove that the resulting graph tends to be Poissonian,\n",
    "we calculate the density of $g$ and plug it in the formula given by *Ricci-Tersenghi et al.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below (also included in IGTools.py) can be used to produce binary graphs from a weighted graph.  \n",
    "In the current form it uses the dumbest possible normalization from weights to probabilities (*normalization by the max weight*) and the most basic probability distribution, but it can readily be generalized to more complex cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_graph_instance(G):\n",
    "    import networkx as nx;\n",
    "    from random import random;\n",
    "    g = nx.Graph();\n",
    "    g.add_nodes_from(G.nodes());\n",
    "    w = nx.get_edge_attributes(G,'weight');\n",
    "    ## this is only the trivial normalization on the maximum edge weight\n",
    "    ## which implies that edge will always be present.\n",
    "    ## different normalizations can easily implemented\n",
    "    w = dict(zip(w.keys(), np.array(w.values()) / float(np.max(w.values()))));\n",
    "    for e in w:\n",
    "        if random()<w[e]:\n",
    "            g.add_edge(e[0],e[1]);\n",
    "    return g;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights on the nodes (tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add Biswadip's proposal about optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
